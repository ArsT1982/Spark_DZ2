{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOxZ4oMsTLzpDDh/de2F3F3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArsT1982/Spark_DZ2/blob/main/Spark_SQL_DZ_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ДЗ-2 (Spark SQL)\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "1eHcdkCoe4QA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подготовка к работе с файлом \"covid-data.csv\" и создание Spark сессии."
      ],
      "metadata": {
        "id": "QSxTzuuBefI0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8Z5u7Akm0TUF"
      },
      "outputs": [],
      "source": [
        "pip install --quiet pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"Practice\").getOrCreate()"
      ],
      "metadata": {
        "id": "sZiVbhx71nSg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkFiles\n",
        "\n",
        "covid_data_file_url = \"https://raw.githubusercontent.com/glincow/netology-spark-sql/main/data/covid-data.csv\"\n",
        "spark.sparkContext.addFile(covid_data_file_url)\n",
        "file_path  = 'file://' + SparkFiles.get('covid-data.csv')\n",
        "df = spark.read.option('inferSchema', 'true').option('header', 'true').csv(file_path)"
      ],
      "metadata": {
        "id": "fsiBhp2Y1rpd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подготовка датасета к работе:\n",
        "Анализ данных и значений в исходном файле.\n",
        "\n",
        "Обнаружил:\n",
        "1. В файле присутствуют null - заменяю эти значения на (0) в датасете.\n",
        "2. В файле присутствуют данные по Евросоюзу (и др. варианты данных вида \"OWID_%\" в поле 'iso_code').\n",
        "Для аналитики важны данные по странам - их и оставил, отсальное исключил из датасета.\n"
      ],
      "metadata": {
        "id": "BHDqVXC_fgPF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "Find_OWID_from_df = df.filter(F.col('iso_code').like('OWID_%'))\n",
        "Exclude_OWID_from_df = df.subtract(Find_OWID_from_df)\n",
        "\n",
        "df_null_to_zero=Exclude_OWID_from_df.na.fill(0)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "fGSvao7MWgdI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задание-1.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Выберите 15 стран с наибольшим процентом переболевших на 31 марта (в выходящем датасете необходимы колонки: iso_code, страна, процент переболевших).\n",
        "\n",
        "\n",
        "---\n",
        "Важно! Посчитал, что переболевшие (alias 'процент переболевших') - это те, кто входит в кол-во в графе общего количества заболевших ('total_cases'), но не относится к графе умерших ('total_deaths'). (\"Переболел - значит выжил\")\n",
        "\n",
        "Посчитал как частное от деления на популяцию, умноженное на 100 (для процентов) и округлил до второго знака.\n",
        "Данные по Евросоюзу были исколючены на предыдущих шагах."
      ],
      "metadata": {
        "id": "nJvA7hszgqiQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "df_perc_recov_by_cntry = df_null_to_zero.select('iso_code', F.col('location').alias('страна'),F.round(((F.col('total_cases')-F.col('total_deaths'))*100.0/F.col('population')),2).alias('процент переболевших')).filter(df_null_to_zero.date == '2020-03-31').sort(F.col('процент переболевших').desc())\n",
        "df_perc_recov_by_cntry.show(15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MCRTca-2B02",
        "outputId": "a5ff3aa9-3f04-4174-f879-bb23e3a597a6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-------------+--------------------+\n",
            "|iso_code|       страна|процент переболевших|\n",
            "+--------+-------------+--------------------+\n",
            "|     VAT|      Vatican|                0.74|\n",
            "|     SMR|   San Marino|                0.62|\n",
            "|     AND|      Andorra|                0.47|\n",
            "|     LUX|   Luxembourg|                0.34|\n",
            "|     ISL|      Iceland|                0.33|\n",
            "|     CHE|  Switzerland|                0.19|\n",
            "|     ESP|        Spain|                0.19|\n",
            "|     LIE|Liechtenstein|                0.18|\n",
            "|     ITA|        Italy|                0.15|\n",
            "|     MCO|       Monaco|                0.13|\n",
            "|     AUT|      Austria|                0.11|\n",
            "|     BEL|      Belgium|                 0.1|\n",
            "|     DEU|      Germany|                0.08|\n",
            "|     NOR|       Norway|                0.08|\n",
            "|     FRA|       France|                0.07|\n",
            "+--------+-------------+--------------------+\n",
            "only showing top 15 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задание-2.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Top 10 стран с максимальным зафиксированным кол-вом новых случаев за последнюю неделю марта 2021 в отсортированном порядке по убыванию\n",
        "(в выходящем датасете необходимы колонки: число, страна, кол-во новых случаев)\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "R4GatmE7jBOe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Отфильтровал весь файл по нужным нам датам 4-ой недели марта 2021.\n",
        "Нашел максимумы кол-ва новых случаев (F.max) применяя оконную функцию партициями по странам.\n",
        "Далее сделал выборку из датасета сравнением с этими ненулевыми максимумами. После этого вывел TOP 10 стран."
      ],
      "metadata": {
        "id": "OV-9Ft4UkO6p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "w = Window.partitionBy(\"страна\")\n",
        "df_new_cases_week = df_null_to_zero.select('iso_code', F.col('location').alias('страна'), F.col('date').alias('дата'), F.col('new_cases').alias('кол-во новых случаев')).filter(df_null_to_zero.date.between ('2021-03-22','2021-03-28')).sort(F.col('страна').asc())\n",
        "Df_window = df_new_cases_week.withColumn(\"new_col\", F.max('кол-во новых случаев').over(w)).sort(F.col('страна').asc())\n",
        "df_result = Df_window.select('страна','дата','кол-во новых случаев').where((F.col('кол-во новых случаев') == F.col('new_col')) & (F.col('new_col') != 0)).sort(F.col('кол-во новых случаев').desc())\n",
        "df_result.show(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGCVYDe3Nqcg",
        "outputId": "cb5acc02-0f15-405b-b73a-6835ab0bc492"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----------+--------------------+\n",
            "|       страна|      дата|кол-во новых случаев|\n",
            "+-------------+----------+--------------------+\n",
            "|       Brazil|2021-03-25|            100158.0|\n",
            "|United States|2021-03-24|             86960.0|\n",
            "|        India|2021-03-28|             68020.0|\n",
            "|       France|2021-03-24|             65392.0|\n",
            "|       Poland|2021-03-26|             35145.0|\n",
            "|       Turkey|2021-03-27|             30021.0|\n",
            "|        Italy|2021-03-22|             24501.0|\n",
            "|      Germany|2021-03-24|             23757.0|\n",
            "|         Peru|2021-03-25|             19206.0|\n",
            "|      Ukraine|2021-03-26|             18226.0|\n",
            "+-------------+----------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "wSaL8GZGs5q3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задание-3.\n",
        "\n",
        "Посчитайте изменение случаев относительно предыдущего дня в России за последнюю неделю марта 2021. (например: в России вчера было 9150 , сегодня 8763, итог: -387) (в выходящем датасете необходимы колонки: число, кол-во новых случаев вчера, кол-во новых случаев сегодня, дельта)\n",
        "\n",
        "Использовал оконную функцию lag для нахождения значения за предыдущий день (alias 'кол-во новых случаев вчера').\n",
        "Для корректного расчета первого дня в выборке в исходном селекте использовал более шировкий диапазон дат - с 21 марта для исключения нуля в результате ф-ции lag.\n",
        "В итоговом результате оставлен период за 4ю неделю с 22 по 28 марта 2021г.\n",
        "Разница с предыдущим днем - alias 'дельта'"
      ],
      "metadata": {
        "id": "FB6IJJjSoQ_u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import lag\n",
        "\n",
        "w = Window.orderBy(\"date\")\n",
        "select_for_df = df_null_to_zero.select('iso_code', 'location', 'date', F.col('new_cases').alias('кол-во новых случаев сегодня')).filter(df_null_to_zero.date.between ('2021-03-21','2021-03-28')).filter(F.col('location').like('Russia')).sort(F.col('date').asc())\n",
        "\n",
        "df_itog = select_for_df.withColumn(\"кол-во новых случаев вчера\", lag('кол-во новых случаев сегодня', 1, 0).over(w))\n",
        "df_result = df_itog.select('date','кол-во новых случаев сегодня','кол-во новых случаев вчера',(F.col('кол-во новых случаев сегодня')-F.col('кол-во новых случаев вчера')).alias('дельта')).filter(df_null_to_zero.date.between ('2021-03-22','2021-03-28'))\n",
        "df_result2 = df_result.select(F.col('date').alias('дата'),'кол-во новых случаев сегодня','кол-во новых случаев вчера','дельта').show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVl5-ftdCFi2",
        "outputId": "932ec319-f219-4ab9-b13b-e5071c88b03f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----------------------------+--------------------------+------+\n",
            "|      дата|кол-во новых случаев сегодня|кол-во новых случаев вчера|дельта|\n",
            "+----------+----------------------------+--------------------------+------+\n",
            "|2021-03-22|                      9195.0|                    9215.0| -20.0|\n",
            "|2021-03-23|                      8369.0|                    9195.0|-826.0|\n",
            "|2021-03-24|                      8769.0|                    8369.0| 400.0|\n",
            "|2021-03-25|                      9128.0|                    8769.0| 359.0|\n",
            "|2021-03-26|                      9073.0|                    9128.0| -55.0|\n",
            "|2021-03-27|                      8783.0|                    9073.0|-290.0|\n",
            "|2021-03-28|                      8979.0|                    8783.0| 196.0|\n",
            "+----------+----------------------------+--------------------------+------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}