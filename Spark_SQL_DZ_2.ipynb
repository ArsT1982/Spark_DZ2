{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN9q6kD+UIG2JpbFIyeCj1V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArsT1982/Spark_DZ2/blob/main/Spark_SQL_DZ_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ДЗ-2 (Spark SQL)\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "1eHcdkCoe4QA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подготовка к работе с файлом \"covid-data.csv\" и создание Spark сессии."
      ],
      "metadata": {
        "id": "QSxTzuuBefI0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8Z5u7Akm0TUF"
      },
      "outputs": [],
      "source": [
        "pip install --quiet pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"Practice\").getOrCreate()"
      ],
      "metadata": {
        "id": "sZiVbhx71nSg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkFiles\n",
        "\n",
        "covid_data_file_url = \"https://raw.githubusercontent.com/glincow/netology-spark-sql/main/data/covid-data.csv\"\n",
        "spark.sparkContext.addFile(covid_data_file_url)\n",
        "file_path  = 'file://' + SparkFiles.get('covid-data.csv')\n",
        "df = spark.read.option('inferSchema', 'true').option('header', 'true').csv(file_path)"
      ],
      "metadata": {
        "id": "fsiBhp2Y1rpd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подготовка датасета к работе:\n",
        "Анализ данных и значений в исходном файле.\n",
        "Обнаружил:\n",
        "1. В файле присутствуют null - заменяем эти значения на 0.\n",
        "2. В файле присутствуют данные по Евросоюзу (и др. OWID_% варианты в поле 'iso_code').\n",
        "Для аналитики важны данные по страны - их и оставил, отсальное исключил.\n"
      ],
      "metadata": {
        "id": "BHDqVXC_fgPF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Find_OWID_from_df = df.filter(F.col('iso_code').like('OWID_%'))\n",
        "Exclude_OWID_from_df = df.subtract(Find_OWID_from_df)\n",
        "#Exclude_OWID_from_df.show()\n",
        "\n",
        "df_null_to_zero=Exclude_OWID_from_df.na.fill(0)\n",
        "#df_null_to_zero.show()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "fGSvao7MWgdI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задание-1.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Выберите 15 стран с наибольшим процентом переболевших на 31 марта (в выходящем датасете необходимы колонки: iso_code, страна, процент переболевших).\n",
        "\n",
        "\n",
        "---\n",
        "Важно! Посчитал, что переболевшие (alias 'recovered') - это те, кто входит в кол-во в графе общего количества заболевших ('total_cases'), но не относится к графе умерших ('total_deaths'). (\"Переболел - значит выжил\")\n",
        "\n",
        "Посчитал как частное от деления на популяцию, умноженное на 100 (для процентов) и округлил до второго знака.\n",
        "Данные по Евросоюзу были исколючены на предыдущих шагах."
      ],
      "metadata": {
        "id": "nJvA7hszgqiQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "df_perc_recov_by_cntry = df_null_to_zero.select('iso_code', 'location',F.round(((F.col('total_cases')-F.col('total_deaths'))*100.0/F.col('population')),2).alias('recovered,%')).filter(df_null_to_zero.date == '2020-03-31').sort(F.col('recovered,%').desc())\n",
        "df_perc_recov_by_cntry.show(15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MCRTca-2B02",
        "outputId": "819cdcd8-9f7e-4ec1-9bd0-e2ab3eaf7d90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-------------+-----------+\n",
            "|iso_code|     location|recovered,%|\n",
            "+--------+-------------+-----------+\n",
            "|     VAT|      Vatican|       0.74|\n",
            "|     SMR|   San Marino|       0.62|\n",
            "|     AND|      Andorra|       0.47|\n",
            "|     LUX|   Luxembourg|       0.34|\n",
            "|     ISL|      Iceland|       0.33|\n",
            "|     CHE|  Switzerland|       0.19|\n",
            "|     ESP|        Spain|       0.19|\n",
            "|     LIE|Liechtenstein|       0.18|\n",
            "|     ITA|        Italy|       0.15|\n",
            "|     MCO|       Monaco|       0.13|\n",
            "|     AUT|      Austria|       0.11|\n",
            "|     BEL|      Belgium|        0.1|\n",
            "|     DEU|      Germany|       0.08|\n",
            "|     NOR|       Norway|       0.08|\n",
            "|     FRA|       France|       0.07|\n",
            "+--------+-------------+-----------+\n",
            "only showing top 15 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задание-2.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Top 10 стран с максимальным зафиксированным кол-вом новых случаев за последнюю неделю марта 2021 в отсортированном порядке по убыванию\n",
        "(в выходящем датасете необходимы колонки: число, страна, кол-во новых случаев)\n",
        "\n",
        "\n",
        "---\n",
        "Посчитал в двух вариантах (т.к. Великий Могучий Русский Язык и можно задание интерпретировать по-разному).\n",
        "\n",
        "Вариант-1:\n",
        "Посчитать Топ 10 стран с самыми большими вспышками (F.max) новых случаев в течении последней (4-ой) недели марта 2021 (по убыванию).\n",
        "\n",
        "Вариант-2:\n",
        "Посчитать Топ 10 стран с самым большим суммарным количеством новых случаев (F.sum) случаев в течении последней (4-ой) недели марта 2021 (по убыванию).\n",
        "\n"
      ],
      "metadata": {
        "id": "R4GatmE7jBOe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вариант-1.\n",
        "\n",
        "---\n",
        "\n",
        "Отфильровал весь файл по нужным нам датам 4ой недели марта 2021.\n",
        "Нашел максимумы (F.max) аггрегатной функции в группировке по странам.\n",
        "Сортировка по убыванию, отображение 10-ти стран."
      ],
      "metadata": {
        "id": "OV-9Ft4UkO6p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "df_new_cases_week = df_null_to_zero.select('iso_code', 'location', 'date', 'new_cases').filter(df_null_to_zero.date.between ('2021-03-22','2021-03-28')).groupBy(\"location\").agg(F.max(\"new_cases\").alias(\"max new cases\")).sort(F.col('max new cases').desc())\n",
        "df_new_cases_week.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFVTE3YeNGYD",
        "outputId": "9cf7fa9c-4225-4975-f82c-b753d682c82e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+-------------+\n",
            "|     location|max new cases|\n",
            "+-------------+-------------+\n",
            "|       Brazil|     100158.0|\n",
            "|United States|      86960.0|\n",
            "|        India|      68020.0|\n",
            "|       France|      65392.0|\n",
            "|       Poland|      35145.0|\n",
            "|       Turkey|      30021.0|\n",
            "|        Italy|      24501.0|\n",
            "|      Germany|      23757.0|\n",
            "|         Peru|      19206.0|\n",
            "|      Ukraine|      18226.0|\n",
            "+-------------+-------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вариант-2.\n",
        "\n",
        "---\n",
        "\n",
        "Отфильровал весь файл по нужным нам датам 4ой недели марта 2021.\n",
        "Нашел суммарные значения (F.sum) аггрегатной функции в группировке по странам.\n",
        "Сортировка по убыванию, отображение 10-ти стран."
      ],
      "metadata": {
        "id": "CBGGKTQIk_Rl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "df_new_cases_week = df_null_to_zero.select('iso_code', 'location', 'date', 'new_cases').filter(df_null_to_zero.date.between ('2021-03-22','2021-03-28')).groupBy(\"location\").agg(F.sum(\"new_cases\").alias(\"max sum new cases\")).sort(F.col('max sum new cases').desc())\n",
        "df_new_cases_week.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cu1w7nd8uMR",
        "outputId": "5bdd7f87-5742-4044-f6b7-f198aba5fa0a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+-----------------+\n",
            "|     location|max sum new cases|\n",
            "+-------------+-----------------+\n",
            "|       Brazil|         536455.0|\n",
            "|United States|         442739.0|\n",
            "|        India|         393563.0|\n",
            "|       France|         263088.0|\n",
            "|       Turkey|         195051.0|\n",
            "|       Poland|         192441.0|\n",
            "|        Italy|         155681.0|\n",
            "|      Germany|         114651.0|\n",
            "|      Ukraine|          98367.0|\n",
            "|         Peru|          63556.0|\n",
            "+-------------+-----------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Как видим - список стран в результатах отличается.\n",
        "Первый список говорит о пиковых значениях (вспышках за данный период, который может коррелировать с событиями - нехватка вакцин, открытие аэропортов, снятие ограничений и т.д.).\n",
        "\n",
        "Второй список стран показывает страны с затяжной тяжелой обстановкой c Covid-19. То есть факторы имеют влияние на более длительном периоде и более репрезентативные с точки зрения глобальных факторов (условно-постоянных) в странах (плотность населения (высокая),  охват вакцинацией (недостаточный),  качество медицины (низкое) и др.)"
      ],
      "metadata": {
        "id": "jeDZ44dvlP5T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задание-3.\n",
        "\n",
        "Посчитайте изменение случаев относительно предыдущего дня в России за последнюю неделю марта 2021. (например: в россии вчера было 9150 , сегодня 8763, итог: -387) (в выходящем датасете необходимы колонки: число, кол-во новых случаев вчера, кол-во новых случаев сегодня, дельта)\n",
        "\n",
        "Использовал оконную функцию lag для нахождения значения за предыдущий день (alias 'yesterday_cases').\n",
        "Для корректного расчета первого дня в выборке в исходном селекте использовал более шировкий диапазон дат - с 21 марта для исключения нуля в результате ф-ции lag.\n",
        "В итоговом результате оставлен период за 4ю неделю с 22 по 28 марта 2021г.\n",
        "Разница с предыдущим днем - alias 'delta'"
      ],
      "metadata": {
        "id": "FB6IJJjSoQ_u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import lag\n",
        "\n",
        "w = Window.orderBy(\"date\")\n",
        "select_for_df = df_null_to_zero.select('iso_code', 'location', 'date', 'new_cases').filter(df_null_to_zero.date.between ('2021-03-21','2021-03-28')).filter(F.col('location').like('Russia')).sort(F.col('date').asc())\n",
        "\n",
        "df_itog = select_for_df.withColumn(\"yesterday_cases\", lag('new_cases', 1, 0).over(w))\n",
        "df_result = df_itog.select('date','new_cases','yesterday_cases',(F.col('new_cases')-F.col('yesterday_cases')).alias('delta')).filter(df_null_to_zero.date.between ('2021-03-22','2021-03-28')).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVl5-ftdCFi2",
        "outputId": "c63faf6a-eba4-4db3-952f-354b0c553c25"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---------+---------------+------+\n",
            "|      date|new_cases|yesterday_cases| delta|\n",
            "+----------+---------+---------------+------+\n",
            "|2021-03-22|   9195.0|         9215.0| -20.0|\n",
            "|2021-03-23|   8369.0|         9195.0|-826.0|\n",
            "|2021-03-24|   8769.0|         8369.0| 400.0|\n",
            "|2021-03-25|   9128.0|         8769.0| 359.0|\n",
            "|2021-03-26|   9073.0|         9128.0| -55.0|\n",
            "|2021-03-27|   8783.0|         9073.0|-290.0|\n",
            "|2021-03-28|   8979.0|         8783.0| 196.0|\n",
            "+----------+---------+---------------+------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}